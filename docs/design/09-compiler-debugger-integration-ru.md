# 09 — Интеграция компилятора и отладчика в CppReason

Как модель видит ошибки, разговаривает с отладчиком и понимает платформу.

---

## Контекст

CppReason — модель, которая говорит на C++. Рассуждает в комментариях C++,
вызывает инструменты через C++-выражения вызова функций, выдаёт C++ код.
Модель не знает и не должна знать про Python, gRPC, GKE, Kubernetes.
Её мир: `.cpp` на входе, `.cpp` на выходе.

Но сейчас есть пробелы:

1. **Ошибки компиляции** приходят как сырой текст stderr — модель тратит
   токены на парсинг формата `file:42:7: error: ...` вместо понимания ошибки
2. **Отладчик** описан в vision-doc (`__AGENT_QUERY__("trace", ...)`) но
   не реализован и не обучен
3. **Платформа** неявна — модель видит `#ifdef _WIN32` в данных, но не знает
   для какой цели генерирует код
4. **Классификация ошибок** не существует — модель не отличает "пропущена
   точка с запятой" от "use-after-free" от "несовместимость ABI"

---

## 1. Как модель должна видеть ошибки компиляции

### Сейчас

`tool_runtime.py` запускает `g++ -fsyntax-only`, возвращает сырой stderr.
`cpp_verifier.py` ловит вывод компилятора для reward в RLVR (0.0 = не
скомпилировалось). Ни тот, ни другой не парсят и не структурируют ошибку.

### Проблема

Сырой вывод компилятора мешает в кучу диагностики, заметки и предложения
по исправлению. Модель тратит ёмкость на разбор строчного формата вместо
понимания сути ошибки.

### Решение: Структурированный формат диагностики

Подаём ошибки как C++ struct literal — формат, который модель уже умеет
читать и писать:

```cpp
// <COMPILE_START>
struct diagnostic {
    const char* file = "vector_sort.cpp";
    int line = 42;
    int col = 7;
    enum severity { error, warning, note } level = error;
    const char* code = "-Werror=return-type";    // флаг clang/gcc
    const char* message = "non-void function does not return a value in all control paths";
    const char* source_line = "    if (v.empty()) { /* пропущен return */ }";
    const char* caret =      "    ^~~~~~~~~~~~~~";
    struct note {
        int line = 38;
        const char* message = "control reaches end of non-void function";
    } notes[1];
};
// <COMPILE_END>
```

### Почему это работает

- Модель уже знает синтаксис C++ struct — **ноль новых типов токенов**
- Имена полей (`line`, `col`, `severity`, `message`) самодокументирующиеся
- `source_line` + `caret` дают пространственный контекст без полного файла
- `notes[]` массив сохраняет цепочки диагностик (template instantiation backtraces)
- `enum severity` позволяет модели отличать ошибки от предупреждений

### Как реализовать

Заменить в `tool_runtime.py::tool_compile()` инъекцию сырого stderr парсером,
который конвертирует gcc/clang диагностики в struct-формат.

Для clang доступен `-fdiagnostics-format=json` (с clang 18) — выдаёт
структурированный JSON, который напрямую маппится на поля struct.
Для gcc — fallback на regex-парсинг стандартного формата `file:line:col: severity: message`.

### Данные для обучения

Генерируем структурированные пары из существующего `diff_sft.jsonl`:
1. Берём код "до" (с багом)
2. Компилируем с `g++ -fdiagnostics-format=json` / clang
3. Форматируем как struct literal
4. Связываем с кодом "после" (исправление)

Получаем ~19K пар `(diagnostic_struct, fix_diff)` из уже имеющихся данных.

---

## 2. Как модель должна разговаривать с отладчиком

### Сейчас

`__AGENT_QUERY__("trace", "HandleRequest")` существует в vision-doc, но:
- не реализован в tool_runtime.py
- нет обучающих данных
- не подключён к реальному отладчику

### Ландшафт исследований (2025-2026)

Три протокола имеют значение:

| Протокол                           | Что делает                                | Кто использует                |
| ---------------------------------- | ----------------------------------------- | ----------------------------- |
| **DAP** (Debug Adapter Protocol)   | Стандартный интерфейс отладчика (VS Code) | GDB, LLDB, Chrome DevTools    |
| **MCP** (Model Context Protocol)   | Стандарт tool calling для LLM             | Claude, ChatDBG, mcp-debugger |
| **LSP** (Language Server Protocol) | Интеллект кода (определения, диагностики) | clangd, rust-analyzer         |

Ключевые системы:
- **ChatDBG** (UMass, FSE 2025): LLM выполняет команды GDB/LLDB напрямую
- **InspectCoder** (Alibaba, окт 2025): LLM ставит breakpoints, инспектирует состояние, итерирует
- **Debug-gym** (Azure AI, сен 2025): текстовая среда pdb для LLM-агентов
- **LLDB MCP** (llvm.org): LLDB теперь нативно поддерживает MCP
- **mcp-debugger** (github.com/debugmcp): MCP-сервер поверх DAP

### Решение: Отладчик как C++ tool calls

Сохраняем C++-нативный принцип. Модель запрашивает действия отладчика
как вызовы C++ функций, runtime переводит их в DAP команды, результаты
возвращаются как C++ struct literals.

**Новые tool-функции** (дополнение к существующим 6):

```cpp
// Поставить breakpoint — возвращает ID
int bp = breakpoint("vector_sort.cpp", 42);

// Условный breakpoint
int bp2 = breakpoint("allocator.cpp", 118, "size > 4096");

// Продолжить выполнение до следующего breakpoint
struct stop_info {
    const char* reason;   // "breakpoint", "signal", "exit"
    const char* file;
    int line;
    int signal;           // 0 если breakpoint, 11 для SIGSEGV и т.д.
} stop = continue_exec();

// Шаг на одну строку исходника
stop_info s = step();

// Инспекция локальных переменных текущего фрейма
struct frame_vars {
    const char* function = "std::vector<int>::push_back";
    const char* file = "stl_vector.h";
    int line = 1198;
    struct var {
        const char* name;
        const char* type;
        const char* value;
    } locals[] = {
        {"this", "std::vector<int>*", "0x7ffd2340"},
        {"__x", "const int&", "42"},
        {"_M_impl", "std::_Vector_base::_Vector_impl",
         "{_M_start=0x55a812, _M_finish=0x55a830, _M_end=0x55a840}"},
    };
} vars = inspect();

// Вычислить выражение в текущем фрейме
const char* result = eval("this->size()");  // возвращает "7"

// Получить backtrace
struct frame {
    int depth;
    const char* function;
    const char* file;
    int line;
} backtrace[] = backtrace_get(/*max_depth=*/10);

// Чтение памяти (для low-level отладки)
struct mem_dump {
    uint64_t address;
    int size;
    const char* hex;     // "48 8b 45 f8 48 89 c7..."
    const char* ascii;   // "H.E.H...."
} mem = read_memory(0x7ffd2340, 64);
```

**Токен `<DEBUG_CONTEXT>` (ID 13)** оборачивает ВЕСЬ вывод отладчика:

```
<DEBUG_CONTEXT>
struct stop_info stop = { .reason = "signal", .signal = 11, ... };
struct frame_vars vars = { .function = "HashMap::insert", ... };
<CODE_END>
```

### Реализация: DAP-бэкенд

tool_runtime оборачивает DAP-клиент (общается с `lldb-dap` или `gdb --interpreter=dap`):

```python
class DebugSession:
    def __init__(self, executable: str, args: list[str]):
        self.dap = DAPClient("lldb-dap")
        self.dap.launch(executable, args)

    def tool_breakpoint(self, file: str, line: int, cond: str = None) -> str:
        bp = self.dap.set_breakpoint(file, line, condition=cond)
        return f"int bp = {bp.id};"

    def tool_continue(self) -> str:
        event = self.dap.continue_and_wait()
        return format_as_cpp_struct("stop_info", event)

    def tool_inspect(self) -> str:
        frame = self.dap.get_top_frame()
        variables = self.dap.get_variables(frame.id)
        return format_as_cpp_struct("frame_vars", frame, variables)
```

### Данные для обучения отладки

Три источника:

**1. Синтетические трассы отладки** из имеющегося C++ корпуса:
- Берём компилируемую функцию
- Вносим известный баг (null deref, off-by-one, use-after-free)
- Компилируем с `-g`, запускаем под GDB/LLDB скриптом
- Захватываем последовательность breakpoint/inspect/backtrace
- Пара: (код с багом + трасса отладки) → исправление

**2. Крэш-дампы из фаззинга**:
- Прогоняем функции через AddressSanitizer/UBSan
- Захватываем отчёты санитайзеров (структурированный формат)
- Форматируем как C++ struct literals
- Модель учится интерпретировать сигнатуры крэшей

**3. Реальные сессии отладки** из GDB-туториалов, StackOverflow:
- Конвертируем транскрипты GDB-сессий в формат C++ struct
- Связываем с исправлением, которое решило проблему

**Ожидаемый объём**: ~50K синтетических трасс, ~5K отчётов санитайзеров,
~10K конвертированных GDB-сессий.

---

## 3. Как модель должна понимать платформы

### Сейчас

Осведомлённость о платформе неявная — модель видит `#ifdef _WIN32` в данных,
но не знает, для какой цели генерирует код.

### Решение: Заголовок контекста платформы

Каждый запрос на генерацию начинается с описания платформы в виде блока
C++ комментариев. Это "системный промпт" модели:

```cpp
// <BOS>
// platform: x86_64-linux-gnu
// compiler: g++ 13.2
// standard: c++20
// mode: user          // user | kernel | firmware
// os: linux 6.1
// arch: x86_64        // x86_64 | aarch64 | riscv64
// features: sse4.2 avx2 avx512f
// libs: boost/1.83 protobuf/4.25 fmt/10.2
// sanitizers: address,undefined
// build: cmake 3.28 / ninja 1.11
// debug: true         // скомпилировано с -g
```

### Почему комментарии (а не struct)

- Комментарии — **токены с нулевой стоимостью** — модель уже их игнорирует/генерирует
- Роль системного промпта без отдельного формата ввода
- Можно препендить к любому контексту без изменения семантики
- Соответствует принципу "всё — .cpp файл"

### Обучение

Добавляем заголовки платформы к обучающим данным:
1. Извлекаем информацию о платформе из билд-систем в C++ корпусе (CMakeLists.txt,
   configure.ac, meson.build → компилятор/стандарт/фичи)
2. Тегируем каждый обучающий документ обнаруженным контекстом платформы
3. Препендим как блок комментариев при токенизации

Модель учится обусловливать вывод контекстом платформы:
- `standard: c++17` → использует `std::optional`, а не `std::expected`
- `mode: kernel` → нет исключений, нет динамических аллокаций, `__attribute__((section))`
- `arch: aarch64` → NEON-интринсики вместо AVX
- `compiler: msvc 19.38` → `__declspec(dllexport)` вместо `__attribute__((visibility))`

### Петля обратной связи по ошибкам

Когда компилятор возвращает ошибку, контекст платформы уже часть разговора.
Модель может сопоставить:

```cpp
// platform: x86_64-linux-gnu, compiler: g++ 13.2, standard: c++20
// <COMPILE_START>
diagnostic d = { .line = 42, .message = "'std::expected' is not a member of 'std'" };
// <COMPILE_END>
/* REASONING: g++ 13.2 с -std=c++20 не имеет std::expected.
   Нужен c++23 или использовать std::variant<T, Error> вместо этого. */
```

---

## 4. Как модель должна классифицировать и рассуждать об ошибках

### Таксономия ошибок

Модель должна научиться категоризировать ошибки в действенные классы.
Выражается через существующий формат `<THOUGHT_START>`:

```cpp
<THOUGHT_START>
/* ERROR_CLASS: type_mismatch
 * SEVERITY: error
 * ROOT_CAUSE: implicit conversion from 'const char*' to 'std::string_view'
 *             requires C++17 but platform specifies C++14
 * FIX_STRATEGY: explicit constructor call
 * CONFIDENCE: 0.95
 */
<THOUGHT_END>
```

Классы ошибок для обучения (метки для RLVR):

| Класс              | Примеры                                          | Паттерн исправления                     |
| ------------------ | ------------------------------------------------ | --------------------------------------- |
| `syntax`           | Пропущена точка с запятой, незакрытые скобки     | Локальная правка                        |
| `type_mismatch`    | Неправильный тип аргумента, плохая конверсия     | Приведение типа                         |
| `undefined_symbol` | Пропущен include, опечатка в имени               | Добавить include / исправить имя        |
| `linker`           | Undefined reference, multiple definition         | Подлинковать библиотеку / исправить ODR |
| `lifetime`         | Use-after-free, висячая ссылка                   | Реструктуризация владения               |
| `concurrency`      | Гонка данных, дедлок                             | Добавить синхронизацию                  |
| `logic`            | Off-by-one, неправильное сравнение               | Исправить алгоритм                      |
| `platform`         | Несовместимость ABI, отсутствующий API           | Условная компиляция                     |
| `resource`         | Утечка памяти, утечка fd                         | RAII-обёртка                            |
| `ub`               | Переполнение знакового, null deref, выравнивание | Исправление по санитайзеру              |

### Обучение классификации ошибок

1. **GSPO-пары** из `cpp_verifier.py`: уже компилирует и получает pass/fail.
   Добавляем метки классификации к reward signal.
2. **Обучение с санитайзерами**: прогоняем скомпилированный код через ASan/UBSan/TSan.
   Каждый отчёт санитайзера маппится в класс ошибки.
3. **Интеграция статического анализа**: прогоняем `clang-tidy` по обучающему коду.
   Каждая диагностика маппится в класс + исправление.

---

## 5. Thinking-токены для структурированного рассуждения

Предложение v2 токенизатора определяет thinking-токены. Вот как они
маппятся на рабочий процесс компилятора/отладчика:

| Токен            | Когда модель его генерирует         | Что следует за ним                                   |
| ---------------- | ----------------------------------- | ---------------------------------------------------- |
| `<THINK_ERROR>`  | После получения диагностики         | Рассуждение о классификации ошибки                   |
| `<THINK_FIX>`    | После классификации                 | Выбор стратегии исправления                          |
| `<THINK_VERIFY>` | После генерации исправления         | Мысленная проверка компиляции                        |
| `<THINK_TRACE>`  | После получения состояния отладчика | Рассуждение о причинно-следственной цепи             |
| `<THINK_PLAN>`   | Перед многошаговой отладкой         | План отладки (какие breakpoints, что инспектировать) |

**Пример многошаговой сессии отладки:**

```
// Входной контекст
<DEBUG_CONTEXT>
struct stop_info stop = { .reason = "signal", .signal = 11,
    .file = "hashmap.cpp", .line = 89 };
struct frame_vars vars = { .function = "HashMap::insert",
    .locals = {
        {"this", "HashMap*", "0x55a812a0"},
        {"key", "const std::string&", "\"hello\""},
        {"bucket", "Bucket*", "0x0"},  // <-- NULL!
    }};
<CODE_END>

// Модель генерирует:
<THINK_TRACE>
/* Сигнал 11 (SIGSEGV) на hashmap.cpp:89 в HashMap::insert.
 * bucket равен NULL (0x0). Значит find_bucket(key) вернул nullptr.
 * Нужно проверить: инициализирована ли хэш-таблица? capacity > 0?
 * ERROR_CLASS: lifetime (разыменование нулевого указателя)
 */
<THINK_END>

<QUERY_TOOL> eval("this->capacity_") <CODE_END>
<TOOL_RESULT> "0" <CODE_END>

<THINK_FIX>
/* capacity_ равен 0 — хэш-таблица не была инициализирована.
 * Корневая причина: конструктор по умолчанию не вызывает init().
 * Исправление: добавить вызов init() в конструктор или ленивую
 * инициализацию в insert().
 */
<THINK_END>

<CODE_START>
// Исправление: ленивая инициализация в insert
void HashMap::insert(const std::string& key, int value) {
    if (capacity_ == 0) { resize(16); }  // <-- добавлено
    Bucket* bucket = find_bucket(key);
    // ... остальное без изменений
}
<CODE_END>
```

---

## 6. Интеграция ChaiScript / Ch

V2-предложение токенизатора упоминает ChaiScript (C++17 header-only
скриптовый движок) и Ch (C/C++ интерпретатор). Они служат конкретной цели:

**Модель может писать исполняемые выражения, которые runtime вычисляет.**

Текущие вызовы типа `compile("...")` передают строковые литералы.
С ChaiScript:

```cpp
// Модель пишет ChaiScript, который runtime исполняет напрямую
<SCRIPT_START>
auto result = run_test("test_insert_empty", [] {
    HashMap m;
    m.insert("key", 42);
    assert(m.size() == 1);
    assert(m.get("key") == 42);
});
if (!result.passed) {
    auto vars = inspect_at(result.crash_file, result.crash_line);
    print(vars);
}
<SCRIPT_END>
```

Это выразительнее синтаксиса функциональных вызовов, потому что поддерживает
поток управления, лямбды и композицию — всё в синтаксисе C++, который
модель уже понимает.

### ChaiScript vs CLING

| Критерий           | ChaiScript                                     | CLING (CERN)                     |
| ------------------ | ---------------------------------------------- | -------------------------------- |
| Установка          | Header-only, C++17                             | Тяжёлый, зависит от Clang/LLVM   |
| Покрытие C++       | Подмножество (нет templates, нет preprocessor) | Полный C++ (это настоящий Clang) |
| Производительность | Интерпретатор                                  | JIT-компиляция через LLVM        |
| Размер             | ~200KB заголовков                              | ~500MB библиотек                 |
| Риск               | Стабильный, MIT                                | Сложная сборка, менее стабилен   |

**Рекомендация**: начать с ChaiScript для простых скриптов (тестирование,
отладочные сценарии), перейти на CLING когда модели понадобится полная
мощность C++ в скриптовом режиме.

---

## 7. Дорожная карта реализации

### Фаза 1: Структурированные диагностики компилятора (можно начать сейчас)

1. Добавить `parse_diagnostic()` в `tool_runtime.py`
2. Добавить путь `-fdiagnostics-format=json` для clang
3. Сгенерировать обучающие пары из `diff_sft.jsonl`
4. Формат: struct literal в `<COMPILE_START>...<COMPILE_END>`
5. Добавить метки классификации ошибок в GSPO reward

**Трудозатраты**: ~2 дня код, ~1 день генерация данных
**Зависимости**: нет — использует существующую инфраструктуру

### Фаза 2: Заголовки контекста платформы (можно начать сейчас)

1. Добавить детекцию платформы в пайплайн данных (`tools/cpp_chunker`)
2. Извлечь compiler/standard/features из CMakeLists.txt в корпусе
3. Препендить блоки комментариев при токенизации
4. Изменения модели не нужны — только данные

**Трудозатраты**: ~3 дня пайплайн данных, ~0 изменений модели
**Зависимости**: доступ к CMakeLists.txt проектов из корпуса

### Фаза 3: Интеграция отладчика (нужна Фаза 1)

1. Реализовать класс `DebugSession` в `tool_runtime.py` обёрткой над DAP
2. Добавить 6 новых tool-функций (breakpoint, continue, step, inspect, eval, backtrace)
3. Форматировать ответы отладчика как C++ struct literals
4. Сгенерировать синтетические трассы отладки для SFT
5. Подключить обработку `<DEBUG_CONTEXT>` в `engine.py`

**Трудозатраты**: ~5 дней код, ~3 дня генерация данных
**Зависимости**: `lldb-dap` или `gdb` с поддержкой DAP

### Фаза 4: Thinking-токены (нужен v2 токенизатор)

1. Реализовать v2 токенизатор с `<THINK_ERROR>`, `<THINK_FIX>`, `<THINK_TRACE>`
2. Добавить паттерны эмиссии thinking-токенов в SFT-данные
3. Обучить модель использовать thinking-токены для рассуждений
4. Добавить маскирование/reward thinking-токенов в RLVR

**Трудозатраты**: ~2 дня токенизатор, ~5 дней данные, обучение ongoing
**Зависимости**: миграция на v2 токенизатор

### Фаза 5: ChaiScript runtime (нужна Фаза 3)

1. Встроить ChaiScript в tool runtime
2. Добавить обработку `<SCRIPT_START>/<SCRIPT_END>`
3. Обучить на скриптованных сессиях отладки
4. Включить композиционное использование инструментов через скриптинг

**Трудозатраты**: ~3 дня runtime, ~5 дней обучающие данные
**Зависимости**: библиотека ChaiScript, v2 токенизатор

---

## 8. Чего модель НЕ должна знать

- Как устроена агентская инфраструктура (Python, gRPC, GKE)
- Как запускать процессы или управлять файлами
- Сетевые протоколы или схемы API
- Собственный обучающий пайплайн

Мир модели: **C++ код на входе, C++ код на выходе.** Всё остальное —
ответственность runtime. Модель не знает, что `compile("...")` запускает
`g++ -fsyntax-only` — она просто знает, что `compile()` возвращает struct
diagnostic, а `inspect()` возвращает struct frame_vars.

---

## 9. Ключевые дизайн-решения

### Почему C++ struct literals (а не JSON, не XML, не специальные токены)

1. **Ноль нового синтаксиса** — модель уже идеально парсит C++
2. **Информация о типах** — `int line = 42` самодокументирующееся, `{"line": 42}` нет
3. **Вложенные структуры** — массивы, вложенные structs, enums работают естественно
4. **Эффективность обучения** — переиспользует существующие паттерны C++ токенов,
   нет доменного сдвига
5. **Композируемость** — модель может генерировать struct literals в своём выводе

### Почему DAP (а не сырые команды GDB/LLDB)

1. **Языконезависимый** — тот же протокол для GDB, LLDB, Chrome DevTools
2. **Структурированный I/O** — JSON-сообщения, а не парсинг текста
3. **Stateful** — сессия с breakpoints, фреймами, переменными
4. **Индустриальный стандарт** — VS Code, JetBrains, Emacs говорят на DAP
5. **Мост к MCP** — DAP чисто маппится в схемы MCP tools если понадобится

### Почему заголовки платформы в комментариях (а не struct, не конфиг)

1. **Нулевая стоимость** — комментарии есть в каждом обучающем документе
2. **Композируемость** — препенд к любому контексту без изменения семантики
3. **Обусловленность** — модель учится кондиционировать вывод на полях платформы
4. **Знакомость** — разработчики пишут комментарии о платформе в реальном коде

---

## 10. Открытые вопросы для обсуждения

1. **Гранулярность struct для ошибок**: Бэктрейсы инстанцирования шаблонов
   (до 50+ строк в C++) раскрывать полностью или суммаризовать?

2. **Область сессии отладчика**: Модель управляет персистентной сессией
   через несколько ходов, или каждый `inspect()` — stateless снимок?

3. **Точность детекции платформы**: Парсинг CMakeLists.txt покрывает ~60%
   корпуса. Также парсить configure.ac, meson.build, Makefile? Или дефолт
   "generic x86_64-linux, c++17, gcc latest"?

4. **ChaiScript vs CLING**: CLING мощнее (полный C++ на Clang), но
   значительно тяжелее. ChaiScript легковесный, но подмножество C++.
   Что лучше подходит?

5. **Объём обучающих данных**: 50K синтетических трасс отладки достаточно
   для обучения отладке, или нужно 500K+? Какое разнообразие типов багов
   необходимо?

6. **Гранулярность thinking-токенов**: 6 thinking-токенов достаточно, или
   модели нужны более детальные маркеры (`<THINK_HYPOTHESIS>`,
   `<THINK_ELIMINATE>`, `<THINK_CONFIRM>`)?

7. **Режимы user/kernel/firmware**: Как глубоко модель должна понимать
   разницу между user-mode и kernel-mode кодом? Достаточно ли комментария
   `// mode: kernel` или нужны отдельные наборы правил (нет exceptions,
   нет dynamic alloc, специфичные API)?
