# Vertex AI Custom Job Configuration for GPU A100 Training
# Uses pre-built PyTorch image with inline setup (no custom container needed)
# 400M Model, 50,000 iterations with FIM 0.4 and CCE kernel
#
# CRITICAL: num_iterations=50000 (FIFTY THOUSAND, NOT 5000!)
#
# Usage: gcloud ai custom-jobs create --region=us-central1 --config=vertex_ai/config/gpu_a100_400M_50k_prebuilt.yaml

displayName: nanochat-d16-400M-vertex-50k

workerPoolSpecs:
  - machineSpec:
      # A100 40GB - best price/performance for 400M model
      machineType: a2-highgpu-1g
      acceleratorType: NVIDIA_TESLA_A100
      acceleratorCount: 1

    replicaCount: 1

    diskSpec:
      bootDiskType: pd-ssd
      bootDiskSizeGb: 200

    containerSpec:
      # Use NVIDIA's pre-built PyTorch container
      imageUri: us-docker.pkg.dev/vertex-ai/training/pytorch-gpu.2-4:latest

      # Run setup and training inline
      command:
        - /bin/bash
        - -c

      args:
        - |
          set -e
          echo "=== Starting nanochat 400M training on Vertex AI ==="
          echo "GPU Info:"
          nvidia-smi
          
          echo ""
          echo "=== Installing dependencies ==="
          pip install --upgrade pip
          pip install wandb tokenizers datasets transformers gcsfs google-cloud-storage psutil tabulate pyarrow
          pip install liger-kernel cut-cross-entropy
          pip install flash-attn --no-build-isolation || echo "Flash attention install failed, continuing..."
          
          echo ""
          echo "=== Downloading training code from GCS ==="
          gsutil -m cp -r gs://nanochat-training-data-2026/code/nanochat /app/
          gsutil -m cp -r gs://nanochat-training-data-2026/code/scripts /app/
          
          cd /app
          export PYTHONPATH=/app
          
          echo ""
          echo "=== Starting training with CORRECT parameters ==="
          echo "depth=16, num_iterations=50000, fim_rate=0.4, kernel=cce"
          
          python -m scripts.base_train \
              --depth=16 \
              --num_iterations=50000 \
              --fim_rate=0.4 \
              --kernel=cce \
              --run=d16_400M_vertex_50k \
              --device_batch_size=32 \
              --total_batch_size=524288 \
              --max_seq_len=2048 \
              --eval_every=1000 \
              --core_metric_every=5000 \
              --warmup_ratio=0.0 \
              --warmdown_ratio=0.4

      # Environment variables
      env:
        - name: HF_TOKEN
          value: "${HF_TOKEN}"
        - name: WANDB_API_KEY
          value: "${WANDB_API_KEY}"
        - name: GOOGLE_CLOUD_PROJECT
          value: "alpine-aspect-459819-m4"
        - name: PYTORCH_CUDA_ALLOC_CONF
          value: "expandable_segments:True"
        - name: WANDB_PROJECT
          value: "nanochat"
        - name: WANDB_ENTITY
          value: "cppcode"
